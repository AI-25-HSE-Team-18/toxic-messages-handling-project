{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Search and merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "---\n",
    "## Notebook contents ##\n",
    "\n",
    "* Collection of the dataset files from the table by the link below \n",
    "* Establishing data types, formats and available values for the initial raw database\n",
    "* Defining of merge recommendations for the initial database\n",
    "* Merge\n",
    "* Studying the basic functionality of the Great Expectations library (additionally-completed)\n",
    "\n",
    "After execution, saving and sharing the dataset with the command is implied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "## Data description and dtypes, values schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "* **raw_text_id (int)** — уникальный идентификатор сырой строки.  \n",
    "\n",
    "* **dataset_id (string)** — идентификатор исходного датасета внутри Google-таблицы;   \n",
    "\n",
    "* **source_platform (string)** — название платформы или ресурса (сайт, форум и т.д.), откуда получен текст.  \n",
    "Информация собиралась эмпирически из источников-описаний датасетов (см. ссылки в таблице).   \n",
    "UPD: не во всех датасетах указаны источники для каждой строки text_raw => некоторые значения в столбце source_platform поданы через запятую как \"шапочные\", общие значения.  \n",
    "* **is_verified (float)** — признак того, была ли исходная разметка верифицирована либо вручную, либо автоматически.  \n",
    "Информация собиралась эмпирически из источников-описаний датасетов.\n",
    "* **text_raw (string)** — исходный текст сообщения без каких-либо предобработок.  \n",
    "* **is_toxic (int)** — бинарный целевой признак токсичности сообщения (1 — токсичное, 0 — нетоксичное).   \n",
    "Допустимые значения: `[0, 1, np.nan]`\n",
    "* **toxicity_type (string)** — мультиклассовый признак, определяющий тип высказывания в более узкой классификации.   \n",
    "Допустимые значения: `[SENSITIVE, INSULT, INAPPROPRIATE, THREAT, OBSCENITY, 'UNKNOWN']`.   \n",
    "UPD: не все бинарные/мультикласс метки присутствуют в разметке, см. в графиках распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "---\n",
    "## Multiclass labels notes\n",
    "### Multiclass labels variations ### \n",
    "* **INAPPROPRIATE** — Неуместное высказывание. \n",
    "* **SENSITIVE** — Чувствительная тема. \n",
    "\n",
    "\n",
    "* **INSULT** — Оскорбление.\n",
    "\n",
    "* **THREAT** — Угроза.\n",
    "* **OBSCENITY** — Непристойность / вульгарность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 'inappropriate' vs 'sensitive' and how to set up `is_toxic` values? ### \n",
    "* INAPPROPRIATE. Главный признак INAPPROPRIATE - неуместный способ подачи сказанного (не соответствующая контексту темы интонация, грубая/вульгарная лексика).    \n",
    "Источник: https://huggingface.co/apanc/russian-inappropriate-messages  \n",
    "Поэтому для метки INAPPROPRIATE **не стоит** однозначно ставить is_toxic=1.   \n",
    "* SENSITIVE. Для этой метки важно содержание темы, а не способ подачи.   \n",
    "Внутри чувствительных тем у высказывания могут быть виды мнений: общественно-неодобряемое и общественно-одобряемое.  \n",
    "Также для SENSITIVE **также не стоит**  однозначно ставить is_toxic=1.  \n",
    "Источник: https://aclanthology.org/2021.bsnlp-1.4\n",
    "* INSULT, THREAT - однозначно is_toxic=1.\n",
    "* ONSCENITY - не стоит ставить is_toxic=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool stuff clears the outputs:\n",
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    !pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import re\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import great_expectations as gx\n",
    "import great_expectations.expectations as gxe \n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"blackmoon/russian-language-toxic-comments\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alexandersemiletov/toxic-russian-comments\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nigula/russianinappropriatemessages\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Set up merging target schema ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target data schema in the result datafra,e: \n",
    "TARGET_SCHEMA = {\n",
    "    'raw_text_id': 'int',\n",
    "    'dataset_id': 'string',\n",
    "    'source_platform': 'string', # name of the site/forum/etc\n",
    "    'is_verified': 'float', # is source data was manually/automaically verified\n",
    "\n",
    "    'text_raw': 'string', # raw text column\n",
    "    'is_toxic': 'int',  # binary target column\n",
    "    'toxicity_type': 'string' # multilabel target column\n",
    "}\n",
    "# note: bunch is a local naming for large mergable datasets from the internet and named in the target_schema as dataset_id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different columns in sub-datasets to be renamed: \n",
    "COLUMNS_MAP = {\n",
    "    'comment': 'text_raw',\n",
    "    'text_message': 'text_raw',\n",
    "    'label_text': 'text_raw',\n",
    "    'text': 'text_raw',\n",
    "    'comments': 'text_raw',\n",
    "    \n",
    "    'toxic': 'is_toxic', \n",
    "    'primary_label': 'toxicity_type',\n",
    "    'toxicity': 'is_toxic',\n",
    "    'hate_speech': 'is_toxic',\n",
    "    'abusive': 'is_toxic',\n",
    "\n",
    "    'source': 'source_platform',\n",
    "    # 'author': 'nickname',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.DataFrame(columns=TARGET_SCHEMA.keys())\n",
    "df_common = df_common.astype(TARGET_SCHEMA)\n",
    "\n",
    "df_common.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Set up path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save dommon df csv: \n",
    "df_common_path = 'data/raw/df_common.csv'\n",
    "\n",
    "# paths of already downloaded datasets from the links (or from the data.zip archive): \n",
    "data_0_path = 'data/raw/data_0/labeled.csv'\n",
    "data_1_txt_path = \"data/raw/data_1/dataset.txt\"  # txt dataset id 1 \n",
    "txt_to_csv_path = 'data/raw/data_1/parsed.csv'   # csv path to save txt dataset 1 \n",
    "data_2_path = 'data/raw/data_2/Inappapropriate_messages.csv'\n",
    "# dataset4 data is not found\n",
    "data_4_train_path = 'data/raw/data_4/train-00000-of-00001.parquet'\n",
    "data_4_test_path = 'data/raw/data_4/test-00000-of-00001.parquet'\n",
    "data_5_path = 'data/raw/data_5/russian_distorted_toxicity.tsv'\n",
    "data_6_path = 'data/raw/data_6/labled.csv'\n",
    "data_7_path = 'data/raw/data_7/final_data.csv'\n",
    "data_8_path = 'data/raw/data_8/sensitive_topics.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Great expectations handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base core great expectations context: \n",
    "context = gx.get_context(mode=\"ephemeral\")\n",
    "\n",
    "# register pd datasrouces: \n",
    "datasource = context.data_sources.add_or_update_pandas(name=\"pandas dataframes\")\n",
    "asset = datasource.add_dataframe_asset(name=\"df_bunch_asset\") # header for structural bunch block\n",
    "batch_definition = asset.add_batch_definition_whole_dataframe(\"bunch\") # structural block for merging dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_validation_results(val_results) -> str:\n",
    "    \"\"\"returns the more readable version of the results\"\"\"\n",
    "    \n",
    "    results_dict = val_results.to_json_dict()\n",
    "        \n",
    "    rows = []\n",
    "    for r in results_dict['results']:\n",
    "        row = {\n",
    "            \"expectation\": r['expectation_config']['type'],\n",
    "            \"column\": r['expectation_config']['kwargs'].get('column'),\n",
    "            \"success\": r['success'],\n",
    "            \"unexpected_count\": r['result'].get('unexpected_count'),\n",
    "            \"unexpected_percent\": r['result'].get('unexpected_percent'),\n",
    "            \"partial_unexpected_list\": r['result'].get('partial_unexpected_list'),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    # filter only incorrect info:   \n",
    "    df_invalid = pd.DataFrame(rows)\n",
    "    df_invalid = df_invalid[df_invalid['success'] == False]\n",
    "    \n",
    "    # more readable version of outputs: \n",
    "    message = (\n",
    "        \"Batch is incorrect! The following expectations failed:\\n\\n\" +\n",
    "        df_invalid.to_string(index=False)\n",
    "    ) \n",
    "\n",
    "    return message\n",
    "\n",
    "def validate_on_intersections(df_merged): \n",
    "    \"\"\"simple validator for merged data\"\"\"\n",
    "\n",
    "    batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df_merged})\n",
    "    validator = context.get_validator(batch=batch)\n",
    "    validator.expect_column_values_to_be_unique(\"text_raw\")\n",
    "    results = validator.validate()\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def validate_df_batch(\n",
    "        df_batch: pd.DataFrame\n",
    "    ):\n",
    "    \"\"\"Great expectations simple workflow for mergable datasets.\n",
    "    df_batch must be composed bassed on TARGET_SCHEMA. \n",
    "    \"\"\"\n",
    "\n",
    "    # create batch from df in terms of batch definition: \n",
    "    batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df_batch})\n",
    "\n",
    "    # Create the batch validator and add its clauses (expectations): \n",
    "    validator = context.get_validator(batch=batch)\n",
    "\n",
    "    for col in TARGET_SCHEMA.keys():\n",
    "        validator.expect_column_to_exist(col)\n",
    "    validator.expect_column_values_to_not_be_null(\"text_raw\")\n",
    "    validator.expect_column_values_to_be_unique(\"text_raw\")\n",
    "\n",
    "    validator.expect_column_values_to_not_match_regex(\"text_raw\", r\"^\\s*$\")\n",
    "    # validator.expect_column_values_to_be_unique(\"raw_text_id\")\n",
    "    validator.expect_column_values_to_be_in_set(\"is_toxic\", [0, 1, ''])\n",
    "    validator.expect_column_values_to_be_in_set(\"is_verified\", [0, 1])\n",
    "\n",
    "    # Soft types checking: \n",
    "    for col, dtype in TARGET_SCHEMA.items():\n",
    "        actual = str(df_batch[col].dtype)\n",
    "        if not actual.startswith(dtype):\n",
    "            print(f\"Warning! Dtype of {col} = {actual}, expected {dtype}\")\n",
    "\n",
    "    # Start validator: \n",
    "    results = validator.validate()\n",
    "\n",
    "    # Check results: \n",
    "    if not results.success:\n",
    "        message = clear_validation_results(results)\n",
    "        raise ValueError(message)\n",
    "    else: \n",
    "        print('Batch is valid!')\n",
    "\n",
    "    return results\n",
    "\n",
    "def merge_on_schema(df: pd.DataFrame, df_bunch: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"df_bunch is the abstract name of large courpuses collected in the internet \n",
    "    (especially passed for this notebook).\n",
    "\n",
    "    validate_df_batch may be used in the another mergable datasets. \n",
    "    \"\"\"\n",
    "\n",
    "    def reset_indexes(df, df_bunch):\n",
    "        \"\"\"Set new index values in df_bunch based on max index found in df\"\"\"\n",
    "\n",
    "        max_existing_id = df[\"raw_text_id\"].max() if not df.empty else -1\n",
    "        # Find rows that have NaN or duplicate raw_text_id in df_bunch and correct them if found: \n",
    "        invalid_mask = df_bunch[\"raw_text_id\"].isna() | df_bunch[\"raw_text_id\"].duplicated()\n",
    "        if invalid_mask.any():\n",
    "            n_invalid = invalid_mask.sum()\n",
    "            print(f\"Warning: {n_invalid} invalid raw_text_id(s) found. Reassigning unique IDs...\")\n",
    "            new_ids = pd.RangeIndex(start=max_existing_id + 1, stop=max_existing_id + 1 + n_invalid)\n",
    "            df_bunch.loc[invalid_mask, \"raw_text_id\"] = new_ids\n",
    "\n",
    "        return df_bunch\n",
    "\n",
    "    # Common check: \n",
    "    validate_df_batch(df_bunch)\n",
    "    \n",
    "    df_bunch = reset_indexes(df, df_bunch)\n",
    "    df_bunch[\"raw_text_id\"] = df_bunch[\"raw_text_id\"].astype(\"int\")\n",
    "\n",
    "    merged_df = pd.merge(df, df_bunch, how='outer')\n",
    "\n",
    "    # check on the intersections of merged dataframe: \n",
    "    inter_results = validate_on_intersections(merged_df)\n",
    "\n",
    "    # hard types: \n",
    "    merged_df['raw_text_id'] = merged_df['raw_text_id'].astype(int)\n",
    "    merged_df['text_raw'] = merged_df['text_raw'].astype('string')\n",
    "    merged_df['source_platform'] = merged_df['source_platform'].astype('string')\n",
    "    # merged_df['nickname'] = merged_df['nickname'].astype('string')\n",
    "        \n",
    "    merged_df['toxicity_type'] = merged_df['toxicity_type'].astype('string')\n",
    "\n",
    "    # if not inter_results.success: \n",
    "    #     try: \n",
    "    #         merged_df = merged_df.drop_duplicates(subset='text_raw', keep='first')\n",
    "    #         mergef_df = reset_indexes(mergef_df)\n",
    "    #     except Exception as ex: \n",
    "    #         print(ex)\n",
    "    #         message = clear_validation_results(inter_results)\n",
    "    #         raise ValueError(message)\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Consider each dataset, transform it to a common view, and merge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## id 0 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.read_csv(data_0_path)\n",
    "data_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = data_0.rename(columns=COLUMNS_MAP)\n",
    "data_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0_bunch = pd.DataFrame(columns=df_common.columns, data=data_0)\n",
    "\n",
    "data_0_bunch['dataset_id'] = 0\n",
    "data_0_bunch['source_platform'] = '2ch, pikabu'\n",
    "data_0_bunch['is_verified'] = 1\n",
    "data_0_bunch['is_toxic'] = data_0_bunch['is_toxic'].astype(int)\n",
    "\n",
    "data_0_bunch['toxicity_type'] = (\n",
    "    data_0_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "\n",
    "data_0_bunch.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(\n",
    "    df=df_common,\n",
    "    df_bunch=data_0_bunch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## id 1 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = \"utf-8\"          \n",
    "\n",
    "# ----- Функция парсинга одной строки -----\n",
    "label_pattern = re.compile(r'^(?:__label__[^ \\t\\r\\n]+(?:,__label__[^ \\t\\r\\n]+)*)')  \n",
    "\n",
    "def parse_line(line: str):\n",
    "    \"\"\"\n",
    "    Возвращает (labels_list, text)\n",
    "    Примеры меток в начале строки:\n",
    "      __label__INSULT текст...\n",
    "      __label__INSULT,__label__THREAT текст...\n",
    "      __label__INSULT,__label__THREAT    текст...\n",
    "    \"\"\"\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    m = label_pattern.match(line)\n",
    "    if not m:\n",
    "        # если строка не начинается с метки — считаем всю строку текстом и без меток\n",
    "        return [], line.strip()\n",
    "    labels_block = m.group(0)\n",
    "    # извлечь отдельные метки, убрать префикс \"__label__\"\n",
    "    raw_labels = [lab.replace(\"__label__\", \"\") for lab in labels_block.split(\",\")]\n",
    "    # текст — остаток строки после меток\n",
    "    text = line[m.end():].strip()\n",
    "    return raw_labels, text\n",
    "\n",
    "# ----- Читаем файл и собираем данные -----\n",
    "rows = []\n",
    "with open(data_1_txt_path, \"r\", encoding=encoding) as f:\n",
    "    for i, ln in enumerate(f, start=1):\n",
    "        if not ln.strip():\n",
    "            # пропускаем пустые строки\n",
    "            continue\n",
    "        labels, text = parse_line(ln)\n",
    "        rows.append({\"text\": text, \"labels\": labels, \"primary_label\": labels[0] if labels else None})\n",
    "\n",
    "# ----- Создаём DataFrame -----\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Loaded rows:\", len(df))\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(txt_to_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv(txt_to_csv_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_1.rename(columns=COLUMNS_MAP)\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_bunch = pd.DataFrame(columns=df_common.columns, data=data_1)\n",
    "\n",
    "data_1_bunch['dataset_id'] = 1\n",
    "data_1_bunch['source_platform'] = 'ok.ru'\n",
    "data_1_bunch['is_verified'] = 1 # data from competiion should be verified usually  \n",
    "\n",
    "data_1_bunch['toxicity_type'] = data_1.loc[:, 'labels'].apply(lambda r: ','.join(ast.literal_eval(r)))\n",
    "data_1_bunch['toxicity_type'] = (\n",
    "    data_1_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "\n",
    "# data_1_bunch['label'] = data_1_bunch['label'].astype(int)\n",
    "data_1_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tox_type(r: str):\n",
    "    if r == 'NORMAL': # normal category \n",
    "        return 0\n",
    "    elif r in ['INSULT', 'THREAT']: # toxic categories  \n",
    "        return 1\n",
    "    else: \n",
    "        return np.nan\n",
    "\n",
    "data_1_bunch['is_toxic'] = data_1_bunch['toxicity_type'].apply(lambda r: set_tox_type(r))\n",
    "\n",
    "data_1_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_bunch.toxicity_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_bunch.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_bunch = data_1_bunch.drop_duplicates(subset='text_raw', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(df_common, data_1_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.to_csv(df_common_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## id 2 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv(data_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why is this distribution so hard-splitted?..\n",
    "plt.hist(x=data_2['inappropriate'], bins=10)\n",
    "# plt.hist(x=pd.read_csv('data/raw/data_2/Inappapropriate_messages_last.csv')['inappropriate'], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = data_2.rename(columns=COLUMNS_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_bunch = pd.DataFrame(columns=df_common.columns, data=data_2)\n",
    "\n",
    "data_2_bunch['dataset_id'] = 2\n",
    "data_2_bunch['source_platform'] = '2ch.hk, Pikabu.ru, answers.mail.ru'\n",
    "\n",
    "# yandex.toloka passed as the labelling method => is_verified=1: \n",
    "data_2_bunch['is_verified'] = 1 \n",
    "\n",
    "data_2_bunch['toxicity_type'] = (\n",
    "    data_2_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "\n",
    "\n",
    "# data_1_bunch['label'] = data_1_bunch['label'].astype(int)\n",
    "data_2_bunch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "The rows in this dataset are named as related to dangerous themes.  \n",
    "=> we can't name those rows as normal, even if INAPPROPRIATE== 0. All those themes are sensitive at least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_bunch['toxicity_type'] = data_2['inappropriate'].apply(lambda r: 'INAPPROPRIATE' if r >= 0.5 else 'SENSITIVE')\n",
    "data_2_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary labels want to be passed and checked in future experiments.\n",
    "data_2_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_bunch.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_bunch.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_bunch = data_2_bunch.drop_duplicates(subset='text_raw', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(df_common, data_2_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_bunch['source_platform'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## id 3 ## \n",
    "data is not found, boooooo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## id 4 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = pd.concat([\n",
    "    pd.read_parquet(data_4_train_path),\n",
    "    pd.read_parquet(data_4_test_path)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels are reversed in this dataset => fix that: \n",
    "data_4.loc[:, 'is_toxic'] = data_4.loc[:, 'label'].apply(lambda x: 1 if x==0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = data_4.rename(columns=COLUMNS_MAP)\n",
    "data_4_bunch = pd.DataFrame(columns=df_common.columns, data=data_4)\n",
    "\n",
    "data_4_bunch['dataset_id'] = 4\n",
    "data_4_bunch['source_platform'] = '2ch, vk' # \n",
    "\n",
    "# hugging face dataset without any information about labelling or corectness. => can't pass it as verified \n",
    "data_4_bunch['is_verified'] = 0 \n",
    "data_4_bunch['toxicity_type'] = (\n",
    "    data_4_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "\n",
    "\n",
    "data_4_bunch['is_toxic'] = data_4_bunch['is_toxic'].astype(int)\n",
    "data_4_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to merge dfs and check out how does the expectations of intersection work: \n",
    "try: \n",
    "    merge_on_schema(df_common, data_4_bunch)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Demo of GE pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "Great expectations is the processing layer that tells us about the problems in dataset to resolve. \n",
    "The specific ouptut of the problem is:   \n",
    "{'success': False, 'expectation_config': {'type': 'expect_column_values_to_not_match_regex', 'kwargs': {'batch_id': 'pandas dataframes-df_bunch_asset', 'column': 'text_raw', 'regex': '^\\\\s*$'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "regex expectation checks on the empty rows => delete them:  \n",
    "also, duplicates with primary df found, => delete duplicates in batch df:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4_bunch[data_4_bunch['text_raw']==''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4_bunch = data_4_bunch[data_4_bunch['text_raw']!='']\n",
    "data_4_bunch= data_4_bunch[~data_4_bunch['text_raw'].isin(df_common['text_raw'])]\n",
    "data_4_bunch = data_4_bunch.drop_duplicates(subset='text_raw')\n",
    "data_4_bunch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "trying to merge one more time => success: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(df_common, data_4_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.to_csv(df_common_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4_bunch['source_platform'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "## id 5 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5 = pd.read_csv(data_5_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5['comments'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5['corrected'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5 = data_5.rename(columns=COLUMNS_MAP)\n",
    "pd.DataFrame(columns=df_common.columns, data=data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_5_bunch = pd.DataFrame(columns=df_common.columns, data=data_5)\n",
    "\n",
    "data_5_bunch['dataset_id'] = 5\n",
    "# data_5_bunch['source_platform'] = 'vk, other' # vk passed explicitly, \"several source data\" named to other\n",
    "# https://github.com/alla-g/toxicity-detection-thesis/tree/main?tab=readme-ov-file\n",
    "\n",
    "\n",
    "data_5_bunch['is_verified'] = 0 \n",
    "data_5_bunch['toxicity_type'] = (\n",
    "    data_5_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "\n",
    "data_5_bunch['is_toxic'] = data_5_bunch['is_toxic'].astype(int)\n",
    "data_5_bunch.dropna(subset='text_raw', inplace=True)\n",
    "\n",
    "data_5_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_bunch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_bunch[~data_5_bunch['text_raw'].isin(df_common['text_raw'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_bunch[~data_5_bunch['text_raw'].isin(df_common['text_raw'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unickness: \n",
    "data_5[~data_5['text_raw'].isin(df_common['text_raw'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_bunch = data_5_bunch[~data_5_bunch['text_raw'].isin(df_common['text_raw'])]\n",
    "data_5_bunch = data_5_bunch[data_5_bunch['text_raw'] != ' ']\n",
    "data_5_bunch.dropna(subset='text_raw', inplace=True)\n",
    "data_5_bunch.drop_duplicates(subset='text_raw', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_bunch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(df_common, data_5_bunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "## id 6 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6 = pd.read_csv(data_6_path)\n",
    "data_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6 = data_6.rename(columns=COLUMNS_MAP)\n",
    "data_6_bunch = pd.DataFrame(columns=df_common.columns, data=data_6)\n",
    "\n",
    "data_6_bunch['dataset_id'] = 6\n",
    "data_6_bunch['source_platform'] = 'YouTube' \n",
    "data_6_bunch['is_verified'] = 0 \n",
    "data_6_bunch['toxicity_type'] = (\n",
    "    data_6_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "\n",
    "data_6_bunch['is_toxic'] = data_6_bunch['is_toxic'].astype(int)\n",
    "# data_6_bunch.dropna(subset='text_raw', inplace=True)\n",
    "\n",
    "data_6_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6_bunch[~data_6_bunch['text_raw'].isin(df_common['text_raw'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6_bunch = data_6_bunch[data_6_bunch['text_raw']!='']\n",
    "data_6_bunch = data_6_bunch[data_6_bunch['text_raw']!=' ']\n",
    "data_6_bunch.dropna(subset='text_raw', inplace=True)\n",
    "data_6_bunch = data_6_bunch.drop_duplicates(subset='text_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_6_bunch.source_platform.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(df_common, data_6_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "## id 7 ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7 = pd.read_csv(data_7_path, sep=';', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7 = data_7.rename(columns=COLUMNS_MAP)\n",
    "data_7_bunch = pd.DataFrame(columns=df_common.columns, data=data_7)\n",
    "\n",
    "data_7_bunch['dataset_id'] = 7\n",
    "data_7_bunch['source_platform'] = 'Social Media, TV-Scripts (South Park)' \n",
    "\n",
    "# info about labeelling is not passed: \n",
    "data_7_bunch['is_verified'] = 0 \n",
    "data_7_bunch['toxicity_type'] = (\n",
    "    data_7_bunch['toxicity_type'].fillna('')\n",
    ").astype(str)\n",
    "data_7_bunch['is_toxic'] = data_7_bunch['is_toxic'].astype(int)\n",
    "\n",
    "data_7_bunch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_7_bunch.drop_duplicates(subset='text_raw', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = merge_on_schema(df_common, data_7_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.to_csv(df_common_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common['is_toxic'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "## id 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8 = pd.read_csv(data_8_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "How much data does each category contain? Is it necessary to add those columns data as a separate multilabel values?  \n",
    "Or is it possible to transform these values into existing labels? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in data_8.columns if col!='text']\n",
    "\n",
    "for col in cols: \n",
    "    print(col)\n",
    "    dat = data_8.loc[data_8[data_8[col]==1].index, :]\n",
    "    print(dat.shape[0])\n",
    "    print(dat.text.values[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "Check the appropriateness: \n",
    "* \"onine/offline crime\" -> THREAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "The data is too heterogeneous to be correctly added to the general dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "## Review of the corectness, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.drop_duplicates(subset='text_raw', inplace=True)\n",
    "df_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.toxicity_type.unique() # <- corrected multiple labels in the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.source_platform.unique() # <- repaired sources (something was wrong in the previous dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common.to_csv(df_common_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "## Conclusions of data collection \n",
    "* Great expectations may be really useful in simple realtime data pipelines. But in the static processing it's slightly redundant (but it's still cool to take a look at this library);\n",
    "* Data imbalance was found in single class labelling (200+k nontoxic vs ~50k toxic). \n",
    "* 455551 rows is a summary count of rows which are include multi- and single labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "### Steps to be done\n",
    "* Run the existing models (ML, DL, LLM/RAG) on the unlabelled data \n",
    "* Find and use the simpliest cloud storage as possible to use in this task to store the raw data, precomputed features and models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "# Visualize data fullness and variety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "**NOTE**: these plots were created to ensure in data fullness and correctness of merge, but the main plots are still in `dataset_eda.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/raw/df_common.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.copy()\n",
    "df_plot['is_toxic'] = df_plot['is_toxic'].fillna('UNKNOWN')\n",
    "df_plot['is_toxic'] = df_plot['is_toxic'].astype(str)\n",
    "\n",
    "toxicity_counts = df_plot.groupby(['toxicity_type', 'is_toxic'], sort=True).size().unstack(fill_value=0)\n",
    "# sort values \n",
    "toxicity_counts['total'] = toxicity_counts.sum(axis=1)\n",
    "toxicity_counts = toxicity_counts.sort_values('total', ascending=False)\n",
    "toxicity_counts = toxicity_counts.drop(columns='total')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "toxicity_counts.plot(kind='bar', stacked=True, ax=ax, width=0.8, alpha=0.7) \n",
    "ax.set_xticks(range(len(toxicity_counts.index)))\n",
    "ax.set_xticklabels(toxicity_counts.index, rotation=20, ha='right')\n",
    "\n",
    "plt.title('Distribution of message types\\n by toxicity', fontsize=14)\n",
    "plt.xlabel('Toxicity type', fontsize=12)\n",
    "plt.ylabel('Messages count', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.legend(title='is_toxic')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "'Obscenity' values are missing in the common eda, but we can still be interested in those "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df['source_platform'].value_counts().plot(kind='bar', color='steelblue')\n",
    "\n",
    "plt.title('Top data platforms\\nfor combined sources', fontsize=14)\n",
    "plt.xlabel('Download platform', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "all_sources = []\n",
    "\n",
    "for item in df['source_platform'].dropna():\n",
    "    parts = [p.strip() for p in item.split(',')]\n",
    "    all_sources.extend(parts)\n",
    "\n",
    "freq_dict = dict(Counter(all_sources))\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    background_color='white',\n",
    "    colormap='viridis',\n",
    "    prefer_horizontal=0.6,\n",
    "    relative_scaling=0.2  \n",
    ").generate_from_frequencies(freq_dict)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Unique platforms word cloud', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "Cool, we checked that nothing was lost of platforms or unique labels!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144",
   "metadata": {},
   "source": [
    "# Check the corectness of labelling using the existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    !pip install .\n",
    "    !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126 \n",
    "    !pip3 install transformers\n",
    "    !nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147",
   "metadata": {},
   "source": [
    "### russian_toxicity_classifier (ID 0, 1 in Datasets table)\n",
    "https://huggingface.co/s-nlp/russian_toxicity_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148",
   "metadata": {},
   "source": [
    "There is only one model in the list above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def inference(model, tokenizer, batch_str):\n",
    "    '''simple inference example for bert-like models'''\n",
    "    try: \n",
    "        batch_str = batch_str.strip() \n",
    "        batch = tokenizer.encode(batch_str, return_tensors='pt')\n",
    "        outp = model(batch)\n",
    "        # outp_int = int(np.argmax(outp))\n",
    "        pred = torch.argmax(outp.logits, dim=1)\n",
    "    except Exception as ex: \n",
    "        print(ex)\n",
    "        pred = np.nan\n",
    "    return pred\n",
    "\n",
    "# load tokenizer and model weights\n",
    "tokenizer = BertTokenizer.from_pretrained('s-nlp/russian_toxicity_classifier')\n",
    "model = BertForSequenceClassification.from_pretrained('s-nlp/russian_toxicity_classifier')\n",
    "\n",
    "max_size = 512 # some messages will be smaller\n",
    "# df['tox_type_model_0'] = df.loc[:, 'text_raw'].apply(lambda r: inference(model, tokenizer, r[:max_size]))\n",
    "# twdm version: \n",
    "tqdm.pandas(desc=\"Toxicity inference\")\n",
    "results = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing texts\"):\n",
    "    text = row['text_raw'][:max_size] if isinstance(row['text_raw'], str) else \"\"\n",
    "    result = inference(model, tokenizer, text)\n",
    "    results.append(result)\n",
    "\n",
    "df['tox_type_model_0'] = pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tox_type_model_0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
